{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "732648af-387c-4c2b-955f-198145f0eec9",
   "metadata": {},
   "source": [
    "## Neural Networks\n",
    "\n",
    "The first approach we used in order to tackle the task was to build a neural network (NN) in order to predict the mass ratio and the chirp mass, so that we could infer their distributions. \n",
    "We opted for this approach due to its flexibility, since the architecture of the network can be adapted and tailored for what is needed, from changing its depth to the activation functions used for each layer, the number of nodes and the objective of the task.\n",
    "In the following sections are presented how the task was modeled and what kind of architectures we tried to use in order to predict the values for the mass ratios and the chirp masses. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bd0f5e2-bb9f-4638-b9e9-49f263363f5d",
   "metadata": {},
   "source": [
    "## Regression Vs Classification\n",
    "Since the quantities of which we want to learn the distribution are continous, the problem can be modeled in different ways depending on how we want to deal with them:\n",
    "* Keeping its continous nature, the task can be formulated as a **regression** where the algorithm, starting from the initial features of each record, try to predict the exact value of the final quantity as close as possible by approximating the complex dependencies from the input values. This task can be become extremely computationally heavy as the complexity of the data increase. This due to the size of the network needed to capture such intricate relatioships;\n",
    "* A different approach in dealing with continous target values is to discretize them by assigning different labels to different ranges of their values. This allows to characterize each data record with its own label. In this case the problem can tackled by classification algorithm which will try to predict the label instead of the exact value of the discretized quantity. As the number of labels increase, the complexity of hte task grows."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa16ebc5-9534-434e-bce1-0500dedfd75f",
   "metadata": {},
   "source": [
    "## Direct Prediction Vs SoftMax Approach\n",
    "\n",
    "In trying to predict the correct label in a classification algorithm its `objective` can be modified in order to gain more insight on what the model is learning. By objective is intended the way the output of the task is presented.\n",
    "In this case we will refer to a direct prediction when the output consists in just the label infered from the initial input values, while an alternative approach can be returing the probability associated with each label to be assigned to a praticular record.\n",
    "By using as the output activation function the `Softmax` function:\n",
    "$$\n",
    "\\sigma(z)_j  = \\frac{e^{z_j}}{\\sum_{k} e^{z_k}}\n",
    "$$\n",
    "Here for each output node value $z_j$, the number of which is equal to the number of possible labels, is associated the probability $\\sigma(z)_j $ of being guessed for the particular record used as input of the NN.\n",
    "By inspecting the resulting probability distribution several quantities can be infered such as the most probable label as well the dispersion of the distribution which can give insight on how well the model is learning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e15d223f-dd6a-4bdd-84da-d6df756954d1",
   "metadata": {},
   "source": [
    "## Tested Architectures\n",
    "For each of the following proposed architecture several variants have been tested in a grid search fashion, in order to improve the capabilities of the algorithms.\n",
    "Due to the extremely complexity of the data neither regression like tasks, as well the classification ones, yielded satisfying results. Every NN is been implemented by the `Pytorch` python package."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "498480ef-9050-4112-ae01-d758a03a63ce",
   "metadata": {},
   "source": [
    "### Regression Architecture\n",
    "The network is designed with fully connected layers that converge into a single output node.\n",
    "In a convolutional network fashion, the algorithm present parallel layers disconnected one from another so that each distinct group can focus on learning different aspects of the input data, for later being recombined into a single value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4565ba4a-4920-4463-8811-8167ff0109f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.in1 = nn.Linear(6,4)\n",
    "        self.in2 = nn.Linear(6,4)\n",
    "        self.in3 = nn.Linear(6,4)\n",
    "        # self.in4 = nn.Linear(6,4)\n",
    "\n",
    "        self.lin1_1 = nn.Linear(4,4)\n",
    "        self.lin1_2 = nn.Linear(4,4)\n",
    "        self.lin1_3 = nn.Linear(4,4)\n",
    "        \n",
    "        self.out = nn.Linear(12,1)\n",
    "\n",
    "    # x represents our data\n",
    "    def forward(self, x):\n",
    "        x1 = self.in1(x)\n",
    "        x1 = torch.relu(x1)\n",
    "        \n",
    "        x1 = self.lin1_1(x1)\n",
    "        x1 = torch.relu(x1)\n",
    "        \n",
    "        x2 = self.in2(x)\n",
    "        x2 = torch.relu(x2)\n",
    "        \n",
    "        x2 = self.lin1_2(x2)\n",
    "        x2 = torch.relu(x2)\n",
    "        \n",
    "        x3 = self.in3(x)\n",
    "        x3 = torch.relu(x3)\n",
    "        \n",
    "        x3 = self.lin1_3(x3)\n",
    "        x3 = torch.relu(x3)\n",
    "        \n",
    "        \n",
    "        output = torch.concat((x1, x2, x3), axis=1)\n",
    "        output = self.out(output)\n",
    "        output = torch.relu(output)\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f48828e0-cb65-4284-9b12-2ea42f16d9b2",
   "metadata": {},
   "source": [
    "<center style=\"margin-left: 10%; margin-right: 10%; background-color: #eeeeee; padding-top: 10px; padding-bottom: 10px;\"><figure><img src=\"Figures/lcp/NN.png\" width=\"60%\" height=\"30%\"><figcaption></figcaption></figure></center><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d42179ec-468c-4f3d-afb2-cde2a72bcd00",
   "metadata": {},
   "source": [
    "<center style=\"margin-left: 10%; margin-right: 10%; background-color: #eeeeee; padding-top: 10px; padding-bottom: 10px;\"><figure><img src=\"Figures/lcp/regression_distribution.png\" width=\"100%\" height=\"30%\"><figcaption></figcaption></figure></center><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce9ea3de-ee1e-4885-acbe-fa477b30b776",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Softmax Architecture\n",
    "The NN is made of fully connected layers of increasing size, which correspond to the number of nodes they are made of.\n",
    "In the final layer, for each output node is computed the softmax function which yield the probability distributiuon of predicting the label for a given input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8cb129b-c102-4a63-a57e-1d777334e82d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.input = nn.Linear(5, 10)\n",
    "        self.linear1 = nn.Linear(10, 15)\n",
    "        self.output = nn.Linear(15, 20)\n",
    "\n",
    "    # x represents our data\n",
    "    def forward(self, x):\n",
    "        x = self.input(x)\n",
    "        x = torch.relu(x)\n",
    "        \n",
    "        x = self.linear1(x)\n",
    "        x = torch.relu(x)\n",
    "        \n",
    "        x = self.output(x)\n",
    "        x = F.softmax(x, dim=0)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f690e29-ef23-4df7-86d9-572a811c0339",
   "metadata": {},
   "source": [
    "<center style=\"margin-left: 10%; margin-right: 10%; background-color: #eeeeee; padding-top: 10px; padding-bottom: 10px;\"><figure><img src=\"Figures/lcp/NNsm.png\" width=\"100%\" height=\"30%\"><figcaption></figcaption></figure></center><br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d722e181-ba2e-43fd-8937-3b813145fde7",
   "metadata": {},
   "source": [
    "<center style=\"margin-left: 10%; margin-right: 10%; background-color: #eeeeee; padding-top: 10px; padding-bottom: 10px;\"><figure><img src=\"Figures/lcp/sm_distribution.png\" width=\"100%\" height=\"30%\"><figcaption></figcaption></figure></center><br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcfb3dd7-5a38-4310-991a-a5a381d80963",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
