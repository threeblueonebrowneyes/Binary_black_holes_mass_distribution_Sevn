{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2125660f",
   "metadata": {},
   "source": [
    "## Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "87a27eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import numpy as np\n",
    "import pandas as pd\n",
    "#import matplotlib.pyplot as plt\n",
    "#import seaborn as sns\n",
    "import re\n",
    "#import time\n",
    "\n",
    "import dask.dataframe as dd\n",
    "#import dask.array as da\n",
    "import dask.bag as db\n",
    "import dask\n",
    "from dask.distributed import Client, SSHCluster\n",
    "import dask.distributed\n",
    "\n",
    "import time\n",
    "\n",
    "# import hvplot.dask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06da6610",
   "metadata": {},
   "source": [
    "## Cluster up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "c04ae0af",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "addf4bef",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-13 14:17:45,427 - distributed.deploy.ssh - INFO - 2023-06-13 14:17:45,426 - distributed.scheduler - INFO - State start\n",
      "2023-06-13 14:17:45,436 - distributed.deploy.ssh - INFO - 2023-06-13 14:17:45,435 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-scratch-space/worker-2ev0j9f0', purging\n",
      "2023-06-13 14:17:45,443 - distributed.deploy.ssh - INFO - 2023-06-13 14:17:45,442 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-scratch-space/worker-zrntlgzx', purging\n",
      "2023-06-13 14:17:45,446 - distributed.deploy.ssh - INFO - 2023-06-13 14:17:45,445 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-scratch-space/worker-bvj8dggn', purging\n",
      "2023-06-13 14:17:45,450 - distributed.deploy.ssh - INFO - 2023-06-13 14:17:45,449 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-scratch-space/worker-9__6_xlx', purging\n",
      "2023-06-13 14:17:45,459 - distributed.deploy.ssh - INFO - 2023-06-13 14:17:45,458 - distributed.scheduler - INFO -   Scheduler at:   tcp://10.67.22.140:8786\n",
      "2023-06-13 14:17:46,384 - distributed.deploy.ssh - INFO - 2023-06-13 14:17:46,382 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.67.22.140:34415'\n",
      "2023-06-13 14:17:46,405 - distributed.deploy.ssh - INFO - 2023-06-13 14:17:46,404 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.67.22.140:41473'\n",
      "2023-06-13 14:17:46,411 - distributed.deploy.ssh - INFO - 2023-06-13 14:17:46,410 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.67.22.140:42425'\n",
      "2023-06-13 14:17:46,421 - distributed.deploy.ssh - INFO - 2023-06-13 14:17:46,420 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.67.22.140:41365'\n",
      "2023-06-13 14:17:47,285 - distributed.deploy.ssh - INFO - 2023-06-13 14:17:47,282 - distributed.worker - INFO -       Start worker at:   tcp://10.67.22.140:46247\n",
      "2023-06-13 14:17:47,287 - distributed.deploy.ssh - INFO - 2023-06-13 14:17:47,282 - distributed.worker - INFO -       Start worker at:   tcp://10.67.22.140:42023\n",
      "2023-06-13 14:17:47,288 - distributed.deploy.ssh - INFO - 2023-06-13 14:17:47,282 - distributed.worker - INFO -          Listening to:   tcp://10.67.22.140:46247\n",
      "2023-06-13 14:17:47,291 - distributed.deploy.ssh - INFO - 2023-06-13 14:17:47,282 - distributed.worker - INFO -          Listening to:   tcp://10.67.22.140:42023\n",
      "2023-06-13 14:17:47,292 - distributed.deploy.ssh - INFO - 2023-06-13 14:17:47,282 - distributed.worker - INFO -          dashboard at:         10.67.22.140:41801\n",
      "2023-06-13 14:17:47,293 - distributed.deploy.ssh - INFO - 2023-06-13 14:17:47,282 - distributed.worker - INFO -          dashboard at:         10.67.22.140:34997\n",
      "2023-06-13 14:17:47,294 - distributed.deploy.ssh - INFO - 2023-06-13 14:17:47,282 - distributed.worker - INFO - Waiting to connect to:    tcp://10.67.22.140:8786\n",
      "2023-06-13 14:17:47,295 - distributed.deploy.ssh - INFO - 2023-06-13 14:17:47,282 - distributed.worker - INFO - Waiting to connect to:    tcp://10.67.22.140:8786\n",
      "2023-06-13 14:17:47,304 - distributed.deploy.ssh - INFO - 2023-06-13 14:17:47,282 - distributed.worker - INFO - -------------------------------------------------\n",
      "2023-06-13 14:17:47,306 - distributed.deploy.ssh - INFO - 2023-06-13 14:17:47,282 - distributed.worker - INFO - -------------------------------------------------\n",
      "2023-06-13 14:17:47,306 - distributed.deploy.ssh - INFO - 2023-06-13 14:17:47,282 - distributed.worker - INFO -               Threads:                          4\n",
      "2023-06-13 14:17:47,307 - distributed.deploy.ssh - INFO - 2023-06-13 14:17:47,282 - distributed.worker - INFO -               Threads:                          4\n",
      "2023-06-13 14:17:47,309 - distributed.deploy.ssh - INFO - 2023-06-13 14:17:47,283 - distributed.worker - INFO -                Memory:                   7.76 GiB\n",
      "2023-06-13 14:17:47,310 - distributed.deploy.ssh - INFO - 2023-06-13 14:17:47,283 - distributed.worker - INFO -                Memory:                   7.76 GiB\n",
      "2023-06-13 14:17:47,311 - distributed.deploy.ssh - INFO - 2023-06-13 14:17:47,283 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-1bjya0ke\n",
      "2023-06-13 14:17:47,311 - distributed.deploy.ssh - INFO - 2023-06-13 14:17:47,283 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-9giqprhs\n",
      "2023-06-13 14:17:47,312 - distributed.deploy.ssh - INFO - 2023-06-13 14:17:47,282 - distributed.worker - INFO -       Start worker at:   tcp://10.67.22.140:45653\n",
      "2023-06-13 14:17:47,314 - distributed.deploy.ssh - INFO - 2023-06-13 14:17:47,283 - distributed.worker - INFO - -------------------------------------------------\n",
      "2023-06-13 14:17:47,315 - distributed.deploy.ssh - INFO - 2023-06-13 14:17:47,283 - distributed.worker - INFO - -------------------------------------------------\n",
      "2023-06-13 14:17:47,316 - distributed.deploy.ssh - INFO - 2023-06-13 14:17:47,283 - distributed.worker - INFO -          Listening to:   tcp://10.67.22.140:45653\n",
      "2023-06-13 14:17:47,317 - distributed.deploy.ssh - INFO - 2023-06-13 14:17:47,283 - distributed.worker - INFO -          dashboard at:         10.67.22.140:42437\n",
      "2023-06-13 14:17:47,318 - distributed.deploy.ssh - INFO - 2023-06-13 14:17:47,283 - distributed.worker - INFO - Waiting to connect to:    tcp://10.67.22.140:8786\n",
      "2023-06-13 14:17:47,319 - distributed.deploy.ssh - INFO - 2023-06-13 14:17:47,283 - distributed.worker - INFO - -------------------------------------------------\n",
      "2023-06-13 14:17:47,320 - distributed.deploy.ssh - INFO - 2023-06-13 14:17:47,284 - distributed.worker - INFO -               Threads:                          4\n",
      "2023-06-13 14:17:47,322 - distributed.deploy.ssh - INFO - 2023-06-13 14:17:47,284 - distributed.worker - INFO -                Memory:                   7.76 GiB\n",
      "2023-06-13 14:17:47,325 - distributed.deploy.ssh - INFO - 2023-06-13 14:17:47,284 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-xo05x1c6\n",
      "2023-06-13 14:17:47,326 - distributed.deploy.ssh - INFO - 2023-06-13 14:17:47,284 - distributed.worker - INFO - -------------------------------------------------\n",
      "2023-06-13 14:17:47,327 - distributed.deploy.ssh - INFO - 2023-06-13 14:17:47,287 - distributed.worker - INFO -       Start worker at:   tcp://10.67.22.140:46097\n",
      "2023-06-13 14:17:47,780 - distributed.deploy.ssh - INFO - 2023-06-13 14:17:47,784 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.67.22.21:39813'\n",
      "2023-06-13 14:17:47,789 - distributed.deploy.ssh - INFO - 2023-06-13 14:17:47,793 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.67.22.21:44845'\n",
      "2023-06-13 14:17:47,792 - distributed.deploy.ssh - INFO - 2023-06-13 14:17:47,796 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.67.22.21:34823'\n",
      "2023-06-13 14:17:47,796 - distributed.deploy.ssh - INFO - 2023-06-13 14:17:47,799 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.67.22.21:36129'\n",
      "2023-06-13 14:17:48,167 - distributed.deploy.ssh - INFO - 2023-06-13 14:17:48,170 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-scratch-space/worker-rxbflgty', purging\n",
      "2023-06-13 14:17:48,169 - distributed.deploy.ssh - INFO - 2023-06-13 14:17:48,171 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-scratch-space/worker-njm5xgds', purging\n",
      "2023-06-13 14:17:48,170 - distributed.deploy.ssh - INFO - 2023-06-13 14:17:48,171 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-scratch-space/worker-cfxduuyx', purging\n",
      "2023-06-13 14:17:48,177 - distributed.deploy.ssh - INFO - 2023-06-13 14:17:48,171 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-scratch-space/worker-3zqvumki', purging\n",
      "2023-06-13 14:17:48,178 - distributed.deploy.ssh - INFO - 2023-06-13 14:17:48,175 - distributed.worker - INFO -       Start worker at:    tcp://10.67.22.21:41471\n",
      "2023-06-13 14:17:48,179 - distributed.deploy.ssh - INFO - 2023-06-13 14:17:48,175 - distributed.worker - INFO -          Listening to:    tcp://10.67.22.21:41471\n",
      "2023-06-13 14:17:48,180 - distributed.deploy.ssh - INFO - 2023-06-13 14:17:48,175 - distributed.worker - INFO -          dashboard at:          10.67.22.21:46209\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-13 14:17:48,182 - distributed.deploy.ssh - INFO - 2023-06-13 14:17:48,175 - distributed.worker - INFO - Waiting to connect to:    tcp://10.67.22.140:8786\n",
      "2023-06-13 14:17:48,184 - distributed.deploy.ssh - INFO - 2023-06-13 14:17:48,175 - distributed.worker - INFO - -------------------------------------------------\n",
      "2023-06-13 14:17:48,185 - distributed.deploy.ssh - INFO - 2023-06-13 14:17:48,175 - distributed.worker - INFO -               Threads:                          4\n",
      "2023-06-13 14:17:48,187 - distributed.deploy.ssh - INFO - 2023-06-13 14:17:48,175 - distributed.worker - INFO -                Memory:                   7.76 GiB\n",
      "2023-06-13 14:17:48,188 - distributed.deploy.ssh - INFO - 2023-06-13 14:17:48,175 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-aao27vm4\n",
      "2023-06-13 14:17:48,189 - distributed.deploy.ssh - INFO - 2023-06-13 14:17:48,175 - distributed.worker - INFO - -------------------------------------------------\n",
      "2023-06-13 14:17:48,204 - distributed.deploy.ssh - INFO - 2023-06-13 14:17:48,187 - distributed.worker - INFO -       Start worker at:    tcp://10.67.22.21:45297\n",
      "2023-06-13 14:17:48,205 - distributed.deploy.ssh - INFO - 2023-06-13 14:17:48,187 - distributed.worker - INFO -          Listening to:    tcp://10.67.22.21:45297\n",
      "2023-06-13 14:17:48,207 - distributed.deploy.ssh - INFO - 2023-06-13 14:17:48,187 - distributed.worker - INFO -          dashboard at:          10.67.22.21:38151\n",
      "2023-06-13 14:17:48,208 - distributed.deploy.ssh - INFO - 2023-06-13 14:17:48,187 - distributed.worker - INFO - Waiting to connect to:    tcp://10.67.22.140:8786\n",
      "2023-06-13 14:17:48,212 - distributed.deploy.ssh - INFO - 2023-06-13 14:17:48,187 - distributed.worker - INFO - -------------------------------------------------\n",
      "2023-06-13 14:17:48,213 - distributed.deploy.ssh - INFO - 2023-06-13 14:17:48,187 - distributed.worker - INFO -               Threads:                          4\n",
      "2023-06-13 14:17:48,215 - distributed.deploy.ssh - INFO - 2023-06-13 14:17:48,187 - distributed.worker - INFO -                Memory:                   7.76 GiB\n",
      "2023-06-13 14:17:48,216 - distributed.deploy.ssh - INFO - 2023-06-13 14:17:48,187 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-u6sx0cyi\n",
      "2023-06-13 14:17:48,217 - distributed.deploy.ssh - INFO - 2023-06-13 14:17:48,187 - distributed.worker - INFO - -------------------------------------------------\n",
      "2023-06-13 14:17:48,219 - distributed.deploy.ssh - INFO - 2023-06-13 14:17:48,188 - distributed.worker - INFO -       Start worker at:    tcp://10.67.22.21:45471\n",
      "2023-06-13 14:17:48,220 - distributed.deploy.ssh - INFO - 2023-06-13 14:17:48,188 - distributed.worker - INFO -          Listening to:    tcp://10.67.22.21:45471\n",
      "2023-06-13 14:17:48,222 - distributed.deploy.ssh - INFO - 2023-06-13 14:17:48,188 - distributed.worker - INFO -          dashboard at:          10.67.22.21:46341\n",
      "2023-06-13 14:17:48,223 - distributed.deploy.ssh - INFO - 2023-06-13 14:17:48,188 - distributed.worker - INFO - Waiting to connect to:    tcp://10.67.22.140:8786\n",
      "2023-06-13 14:17:48,224 - distributed.deploy.ssh - INFO - 2023-06-13 14:17:48,188 - distributed.worker - INFO - -------------------------------------------------\n",
      "2023-06-13 14:17:48,226 - distributed.deploy.ssh - INFO - 2023-06-13 14:17:48,188 - distributed.worker - INFO -               Threads:                          4\n",
      "2023-06-13 14:17:48,227 - distributed.deploy.ssh - INFO - 2023-06-13 14:17:48,188 - distributed.worker - INFO -                Memory:                   7.76 GiB\n",
      "2023-06-13 14:17:48,228 - distributed.deploy.ssh - INFO - 2023-06-13 14:17:48,188 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-5c3zm7q4\n",
      "2023-06-13 14:17:48,231 - distributed.deploy.ssh - INFO - 2023-06-13 14:17:48,188 - distributed.worker - INFO - -------------------------------------------------\n",
      "2023-06-13 14:17:48,237 - distributed.deploy.ssh - INFO - 2023-06-13 14:17:48,207 - distributed.worker - INFO -       Start worker at:    tcp://10.67.22.21:45137\n",
      "2023-06-13 14:17:50,466 - distributed.deploy.ssh - INFO - 2023-06-13 14:17:50,468 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.67.22.220:36331'\n",
      "2023-06-13 14:17:50,476 - distributed.deploy.ssh - INFO - 2023-06-13 14:17:50,480 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.67.22.220:40707'\n",
      "2023-06-13 14:17:50,480 - distributed.deploy.ssh - INFO - 2023-06-13 14:17:50,483 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.67.22.220:45597'\n",
      "2023-06-13 14:17:50,483 - distributed.deploy.ssh - INFO - 2023-06-13 14:17:50,487 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.67.22.220:43705'\n",
      "2023-06-13 14:17:51,105 - distributed.deploy.ssh - INFO - 2023-06-13 14:17:51,106 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-scratch-space/worker-hgaliyse', purging\n",
      "2023-06-13 14:17:51,107 - distributed.deploy.ssh - INFO - 2023-06-13 14:17:51,107 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-scratch-space/worker-plm5a9o8', purging\n",
      "2023-06-13 14:17:51,110 - distributed.deploy.ssh - INFO - 2023-06-13 14:17:51,107 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-scratch-space/worker-g5hnzjih', purging\n",
      "2023-06-13 14:17:51,111 - distributed.deploy.ssh - INFO - 2023-06-13 14:17:51,108 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-scratch-space/worker-cert51ii', purging\n",
      "2023-06-13 14:17:51,154 - distributed.deploy.ssh - INFO - 2023-06-13 14:17:51,154 - distributed.worker - INFO -       Start worker at:   tcp://10.67.22.220:45927\n",
      "2023-06-13 14:17:51,156 - distributed.deploy.ssh - INFO - 2023-06-13 14:17:51,155 - distributed.worker - INFO -          Listening to:   tcp://10.67.22.220:45927\n",
      "2023-06-13 14:17:51,157 - distributed.deploy.ssh - INFO - 2023-06-13 14:17:51,155 - distributed.worker - INFO -          dashboard at:         10.67.22.220:40441\n",
      "2023-06-13 14:17:51,158 - distributed.deploy.ssh - INFO - 2023-06-13 14:17:51,155 - distributed.worker - INFO - Waiting to connect to:    tcp://10.67.22.140:8786\n",
      "2023-06-13 14:17:51,159 - distributed.deploy.ssh - INFO - 2023-06-13 14:17:51,155 - distributed.worker - INFO - -------------------------------------------------\n",
      "2023-06-13 14:17:51,161 - distributed.deploy.ssh - INFO - 2023-06-13 14:17:51,155 - distributed.worker - INFO -               Threads:                          4\n",
      "2023-06-13 14:17:51,162 - distributed.deploy.ssh - INFO - 2023-06-13 14:17:51,155 - distributed.worker - INFO -                Memory:                   7.76 GiB\n",
      "2023-06-13 14:17:51,162 - distributed.deploy.ssh - INFO - 2023-06-13 14:17:51,155 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-6jwtw_mq\n",
      "2023-06-13 14:17:51,163 - distributed.deploy.ssh - INFO - 2023-06-13 14:17:51,155 - distributed.worker - INFO - -------------------------------------------------\n",
      "2023-06-13 14:17:51,177 - distributed.deploy.ssh - INFO - 2023-06-13 14:17:51,179 - distributed.worker - INFO -       Start worker at:   tcp://10.67.22.220:34099\n",
      "2023-06-13 14:17:51,178 - distributed.deploy.ssh - INFO - 2023-06-13 14:17:51,179 - distributed.worker - INFO -          Listening to:   tcp://10.67.22.220:34099\n",
      "2023-06-13 14:17:51,180 - distributed.deploy.ssh - INFO - 2023-06-13 14:17:51,179 - distributed.worker - INFO -          dashboard at:         10.67.22.220:36861\n",
      "2023-06-13 14:17:51,182 - distributed.deploy.ssh - INFO - 2023-06-13 14:17:51,179 - distributed.worker - INFO - Waiting to connect to:    tcp://10.67.22.140:8786\n",
      "2023-06-13 14:17:51,188 - distributed.deploy.ssh - INFO - 2023-06-13 14:17:51,179 - distributed.worker - INFO - -------------------------------------------------\n",
      "2023-06-13 14:17:51,189 - distributed.deploy.ssh - INFO - 2023-06-13 14:17:51,180 - distributed.worker - INFO -               Threads:                          4\n",
      "2023-06-13 14:17:51,190 - distributed.deploy.ssh - INFO - 2023-06-13 14:17:51,180 - distributed.worker - INFO -                Memory:                   7.76 GiB\n",
      "2023-06-13 14:17:51,191 - distributed.deploy.ssh - INFO - 2023-06-13 14:17:51,180 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-rys9mtr2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-13 14:17:51,192 - distributed.deploy.ssh - INFO - 2023-06-13 14:17:51,180 - distributed.worker - INFO - -------------------------------------------------\n",
      "2023-06-13 14:17:51,193 - distributed.deploy.ssh - INFO - 2023-06-13 14:17:51,180 - distributed.worker - INFO -       Start worker at:   tcp://10.67.22.220:33507\n",
      "2023-06-13 14:17:51,194 - distributed.deploy.ssh - INFO - 2023-06-13 14:17:51,181 - distributed.worker - INFO -          Listening to:   tcp://10.67.22.220:33507\n",
      "2023-06-13 14:17:51,195 - distributed.deploy.ssh - INFO - 2023-06-13 14:17:51,181 - distributed.worker - INFO -          dashboard at:         10.67.22.220:34003\n",
      "2023-06-13 14:17:51,196 - distributed.deploy.ssh - INFO - 2023-06-13 14:17:51,181 - distributed.worker - INFO - Waiting to connect to:    tcp://10.67.22.140:8786\n",
      "2023-06-13 14:17:51,199 - distributed.deploy.ssh - INFO - 2023-06-13 14:17:51,181 - distributed.worker - INFO - -------------------------------------------------\n",
      "2023-06-13 14:17:51,200 - distributed.deploy.ssh - INFO - 2023-06-13 14:17:51,181 - distributed.worker - INFO -               Threads:                          4\n",
      "2023-06-13 14:17:51,201 - distributed.deploy.ssh - INFO - 2023-06-13 14:17:51,181 - distributed.worker - INFO -                Memory:                   7.76 GiB\n",
      "2023-06-13 14:17:51,202 - distributed.deploy.ssh - INFO - 2023-06-13 14:17:51,182 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-ymho6stv\n",
      "2023-06-13 14:17:51,202 - distributed.deploy.ssh - INFO - 2023-06-13 14:17:51,182 - distributed.worker - INFO - -------------------------------------------------\n",
      "2023-06-13 14:17:51,219 - distributed.deploy.ssh - INFO - 2023-06-13 14:17:51,221 - distributed.worker - INFO -       Start worker at:   tcp://10.67.22.220:43201\n",
      "2023-06-13 14:17:51,295 - distributed.deploy.ssh - INFO - 2023-06-13 14:17:51,295 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.67.22.81:34797'\n",
      "2023-06-13 14:17:51,310 - distributed.deploy.ssh - INFO - 2023-06-13 14:17:51,309 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.67.22.81:34823'\n",
      "2023-06-13 14:17:51,313 - distributed.deploy.ssh - INFO - 2023-06-13 14:17:51,312 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.67.22.81:36341'\n",
      "2023-06-13 14:17:51,318 - distributed.deploy.ssh - INFO - 2023-06-13 14:17:51,318 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.67.22.81:32803'\n",
      "2023-06-13 14:17:51,577 - distributed.deploy.ssh - INFO - 2023-06-13 14:17:51,583 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.67.22.31:39131'\n",
      "2023-06-13 14:17:51,596 - distributed.deploy.ssh - INFO - 2023-06-13 14:17:51,603 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.67.22.31:42165'\n",
      "2023-06-13 14:17:51,598 - distributed.deploy.ssh - INFO - 2023-06-13 14:17:51,605 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.67.22.31:34267'\n",
      "2023-06-13 14:17:51,602 - distributed.deploy.ssh - INFO - 2023-06-13 14:17:51,609 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.67.22.31:34593'\n",
      "2023-06-13 14:17:52,034 - distributed.deploy.ssh - INFO - 2023-06-13 14:17:52,034 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-scratch-space/worker-0fhl3avl', purging\n",
      "2023-06-13 14:17:52,038 - distributed.deploy.ssh - INFO - 2023-06-13 14:17:52,034 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-scratch-space/worker-75eikyun', purging\n",
      "2023-06-13 14:17:52,039 - distributed.deploy.ssh - INFO - 2023-06-13 14:17:52,035 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-scratch-space/worker-vrmmb85k', purging\n",
      "2023-06-13 14:17:52,040 - distributed.deploy.ssh - INFO - 2023-06-13 14:17:52,036 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-scratch-space/worker-ari9f8vi', purging\n",
      "2023-06-13 14:17:52,122 - distributed.deploy.ssh - INFO - 2023-06-13 14:17:52,121 - distributed.worker - INFO -       Start worker at:    tcp://10.67.22.81:34855\n",
      "2023-06-13 14:17:52,123 - distributed.deploy.ssh - INFO - 2023-06-13 14:17:52,121 - distributed.worker - INFO -       Start worker at:    tcp://10.67.22.81:41975\n",
      "2023-06-13 14:17:52,125 - distributed.deploy.ssh - INFO - 2023-06-13 14:17:52,121 - distributed.worker - INFO -       Start worker at:    tcp://10.67.22.81:33711\n",
      "2023-06-13 14:17:52,126 - distributed.deploy.ssh - INFO - 2023-06-13 14:17:52,121 - distributed.worker - INFO -          Listening to:    tcp://10.67.22.81:33711\n",
      "2023-06-13 14:17:52,128 - distributed.deploy.ssh - INFO - 2023-06-13 14:17:52,121 - distributed.worker - INFO -          Listening to:    tcp://10.67.22.81:41975\n",
      "2023-06-13 14:17:52,129 - distributed.deploy.ssh - INFO - 2023-06-13 14:17:52,121 - distributed.worker - INFO -          dashboard at:          10.67.22.81:43727\n",
      "2023-06-13 14:17:52,141 - distributed.deploy.ssh - INFO - 2023-06-13 14:17:52,121 - distributed.worker - INFO -          dashboard at:          10.67.22.81:36535\n",
      "2023-06-13 14:17:52,142 - distributed.deploy.ssh - INFO - 2023-06-13 14:17:52,121 - distributed.worker - INFO - Waiting to connect to:    tcp://10.67.22.140:8786\n",
      "2023-06-13 14:17:52,143 - distributed.deploy.ssh - INFO - 2023-06-13 14:17:52,121 - distributed.worker - INFO - Waiting to connect to:    tcp://10.67.22.140:8786\n",
      "2023-06-13 14:17:52,144 - distributed.deploy.ssh - INFO - 2023-06-13 14:17:52,121 - distributed.worker - INFO - -------------------------------------------------\n",
      "2023-06-13 14:17:52,147 - distributed.deploy.ssh - INFO - 2023-06-13 14:17:52,121 - distributed.worker - INFO - -------------------------------------------------\n",
      "2023-06-13 14:17:52,148 - distributed.deploy.ssh - INFO - 2023-06-13 14:17:52,121 - distributed.worker - INFO -               Threads:                          4\n",
      "2023-06-13 14:17:52,149 - distributed.deploy.ssh - INFO - 2023-06-13 14:17:52,121 - distributed.worker - INFO -               Threads:                          4\n",
      "2023-06-13 14:17:52,150 - distributed.deploy.ssh - INFO - 2023-06-13 14:17:52,121 - distributed.worker - INFO -                Memory:                   7.76 GiB\n",
      "2023-06-13 14:17:52,151 - distributed.deploy.ssh - INFO - 2023-06-13 14:17:52,121 - distributed.worker - INFO -                Memory:                   7.76 GiB\n",
      "2023-06-13 14:17:52,152 - distributed.deploy.ssh - INFO - 2023-06-13 14:17:52,121 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-trj0_c4m\n",
      "2023-06-13 14:17:52,154 - distributed.deploy.ssh - INFO - 2023-06-13 14:17:52,121 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-zjvm590k\n",
      "2023-06-13 14:17:52,155 - distributed.deploy.ssh - INFO - 2023-06-13 14:17:52,122 - distributed.worker - INFO - -------------------------------------------------\n",
      "2023-06-13 14:17:52,156 - distributed.deploy.ssh - INFO - 2023-06-13 14:17:52,122 - distributed.worker - INFO - -------------------------------------------------\n",
      "2023-06-13 14:17:52,157 - distributed.deploy.ssh - INFO - 2023-06-13 14:17:52,122 - distributed.worker - INFO -          Listening to:    tcp://10.67.22.81:34855\n",
      "2023-06-13 14:17:52,158 - distributed.deploy.ssh - INFO - 2023-06-13 14:17:52,122 - distributed.worker - INFO -          dashboard at:          10.67.22.81:39049\n",
      "2023-06-13 14:17:52,159 - distributed.deploy.ssh - INFO - 2023-06-13 14:17:52,122 - distributed.worker - INFO - Waiting to connect to:    tcp://10.67.22.140:8786\n",
      "2023-06-13 14:17:52,159 - distributed.deploy.ssh - INFO - 2023-06-13 14:17:52,122 - distributed.worker - INFO - -------------------------------------------------\n",
      "2023-06-13 14:17:52,160 - distributed.deploy.ssh - INFO - 2023-06-13 14:17:52,123 - distributed.worker - INFO -               Threads:                          4\n",
      "2023-06-13 14:17:52,164 - distributed.deploy.ssh - INFO - 2023-06-13 14:17:52,123 - distributed.worker - INFO -                Memory:                   7.76 GiB\n",
      "2023-06-13 14:17:52,164 - distributed.deploy.ssh - INFO - 2023-06-13 14:17:52,123 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-8l1vk5f7\n",
      "2023-06-13 14:17:52,165 - distributed.deploy.ssh - INFO - 2023-06-13 14:17:52,123 - distributed.worker - INFO - -------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-13 14:17:52,167 - distributed.deploy.ssh - INFO - 2023-06-13 14:17:52,128 - distributed.worker - INFO -       Start worker at:    tcp://10.67.22.81:35641\n",
      "2023-06-13 14:17:52,238 - distributed.deploy.ssh - INFO - 2023-06-13 14:17:52,245 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-scratch-space/worker-5cptecps', purging\n",
      "2023-06-13 14:17:52,241 - distributed.deploy.ssh - INFO - 2023-06-13 14:17:52,245 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-scratch-space/worker-6v_rm8xu', purging\n",
      "2023-06-13 14:17:52,241 - distributed.deploy.ssh - INFO - 2023-06-13 14:17:52,246 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-scratch-space/worker-17ohys0n', purging\n",
      "2023-06-13 14:17:52,242 - distributed.deploy.ssh - INFO - 2023-06-13 14:17:52,246 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-scratch-space/worker-lc4ea_p6', purging\n",
      "2023-06-13 14:17:52,247 - distributed.deploy.ssh - INFO - 2023-06-13 14:17:52,254 - distributed.worker - INFO -       Start worker at:    tcp://10.67.22.31:37207\n",
      "2023-06-13 14:17:52,248 - distributed.deploy.ssh - INFO - 2023-06-13 14:17:52,254 - distributed.worker - INFO -          Listening to:    tcp://10.67.22.31:37207\n",
      "2023-06-13 14:17:52,249 - distributed.deploy.ssh - INFO - 2023-06-13 14:17:52,254 - distributed.worker - INFO -          dashboard at:          10.67.22.31:39901\n",
      "2023-06-13 14:17:52,250 - distributed.deploy.ssh - INFO - 2023-06-13 14:17:52,254 - distributed.worker - INFO - Waiting to connect to:    tcp://10.67.22.140:8786\n",
      "2023-06-13 14:17:52,252 - distributed.deploy.ssh - INFO - 2023-06-13 14:17:52,254 - distributed.worker - INFO - -------------------------------------------------\n",
      "2023-06-13 14:17:52,253 - distributed.deploy.ssh - INFO - 2023-06-13 14:17:52,254 - distributed.worker - INFO -               Threads:                          4\n",
      "2023-06-13 14:17:52,254 - distributed.deploy.ssh - INFO - 2023-06-13 14:17:52,254 - distributed.worker - INFO -                Memory:                   7.76 GiB\n",
      "2023-06-13 14:17:52,255 - distributed.deploy.ssh - INFO - 2023-06-13 14:17:52,254 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-hsgtinfg\n",
      "2023-06-13 14:17:52,256 - distributed.deploy.ssh - INFO - 2023-06-13 14:17:52,254 - distributed.worker - INFO - -------------------------------------------------\n",
      "2023-06-13 14:17:52,260 - distributed.deploy.ssh - INFO - 2023-06-13 14:17:52,266 - distributed.worker - INFO -       Start worker at:    tcp://10.67.22.31:37283\n",
      "2023-06-13 14:17:52,261 - distributed.deploy.ssh - INFO - 2023-06-13 14:17:52,266 - distributed.worker - INFO -          Listening to:    tcp://10.67.22.31:37283\n",
      "2023-06-13 14:17:52,262 - distributed.deploy.ssh - INFO - 2023-06-13 14:17:52,266 - distributed.worker - INFO -          dashboard at:          10.67.22.31:34269\n",
      "2023-06-13 14:17:52,264 - distributed.deploy.ssh - INFO - 2023-06-13 14:17:52,266 - distributed.worker - INFO - Waiting to connect to:    tcp://10.67.22.140:8786\n",
      "2023-06-13 14:17:52,265 - distributed.deploy.ssh - INFO - 2023-06-13 14:17:52,266 - distributed.worker - INFO - -------------------------------------------------\n",
      "2023-06-13 14:17:52,266 - distributed.deploy.ssh - INFO - 2023-06-13 14:17:52,266 - distributed.worker - INFO -               Threads:                          4\n",
      "2023-06-13 14:17:52,267 - distributed.deploy.ssh - INFO - 2023-06-13 14:17:52,266 - distributed.worker - INFO -                Memory:                   7.76 GiB\n",
      "2023-06-13 14:17:52,269 - distributed.deploy.ssh - INFO - 2023-06-13 14:17:52,266 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-yrdotgry\n",
      "2023-06-13 14:17:52,271 - distributed.deploy.ssh - INFO - 2023-06-13 14:17:52,266 - distributed.worker - INFO - -------------------------------------------------\n",
      "2023-06-13 14:17:52,284 - distributed.deploy.ssh - INFO - 2023-06-13 14:17:52,271 - distributed.worker - INFO -       Start worker at:    tcp://10.67.22.31:45933\n",
      "2023-06-13 14:17:52,285 - distributed.deploy.ssh - INFO - 2023-06-13 14:17:52,271 - distributed.worker - INFO -          Listening to:    tcp://10.67.22.31:45933\n",
      "2023-06-13 14:17:52,286 - distributed.deploy.ssh - INFO - 2023-06-13 14:17:52,272 - distributed.worker - INFO -          dashboard at:          10.67.22.31:34591\n",
      "2023-06-13 14:17:52,287 - distributed.deploy.ssh - INFO - 2023-06-13 14:17:52,272 - distributed.worker - INFO - Waiting to connect to:    tcp://10.67.22.140:8786\n",
      "2023-06-13 14:17:52,289 - distributed.deploy.ssh - INFO - 2023-06-13 14:17:52,272 - distributed.worker - INFO - -------------------------------------------------\n",
      "2023-06-13 14:17:52,291 - distributed.deploy.ssh - INFO - 2023-06-13 14:17:52,272 - distributed.worker - INFO -               Threads:                          4\n",
      "2023-06-13 14:17:52,292 - distributed.deploy.ssh - INFO - 2023-06-13 14:17:52,272 - distributed.worker - INFO -                Memory:                   7.76 GiB\n",
      "2023-06-13 14:17:52,293 - distributed.deploy.ssh - INFO - 2023-06-13 14:17:52,272 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-b552eisn\n",
      "2023-06-13 14:17:52,295 - distributed.deploy.ssh - INFO - 2023-06-13 14:17:52,273 - distributed.worker - INFO - -------------------------------------------------\n",
      "2023-06-13 14:17:52,305 - distributed.deploy.ssh - INFO - 2023-06-13 14:17:52,284 - distributed.worker - INFO -       Start worker at:    tcp://10.67.22.31:45423\n"
     ]
    }
   ],
   "source": [
    "cluster = SSHCluster(\n",
    "            [\"bhbh-1\", 'bhbh-1', \"bhbh-2\", \"bhbh-3\", \"bhbh-4\", \"bhbh-5\"],\n",
    "            connect_options={\"client_keys\": \"/home/ubuntu/private/tbertola_key.pem\"},\n",
    "            worker_options={\"n_workers\": 4,\n",
    "                            \"nthreads\": 4}, # because each bhbh-* has 4 cores\n",
    "            scheduler_options={\"port\": 8786, \"dashboard_address\": \":8787\"}\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "784e8a68",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/lib/python3.10/site-packages/distributed/client.py:1388: VersionMismatchWarning: Mismatched versions found\n",
      "\n",
      "+---------+--------+-----------+------------------+\n",
      "| Package | Client | Scheduler | Workers          |\n",
      "+---------+--------+-----------+------------------+\n",
      "| tornado | 6.3.2  | 6.3.2     | {'6.3.2', '6.2'} |\n",
      "+---------+--------+-----------+------------------+\n",
      "  warnings.warn(version_module.VersionMismatchWarning(msg[0][\"warning\"]))\n"
     ]
    }
   ],
   "source": [
    "client=Client(cluster)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce32d976",
   "metadata": {},
   "source": [
    "## Client "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "9825c3b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cluster.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe9a114c",
   "metadata": {},
   "source": [
    "## Creating list of directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "d93bc6c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "dir_path = '/mnt/bhbh/fiducial_Hrad_5M/sevn_output_*'\n",
    "dir_list = glob.glob(dir_path)\n",
    "print(len(dir_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b686bc1f",
   "metadata": {},
   "source": [
    "## Creating the bag of bags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "8f0688d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "bag=db.from_sequence([db.from_sequence([dir_ + f'/0/output_{thread}.csv', \n",
    "          dir_ + f'/0/evolved_{thread}.dat',\n",
    "          dir_ + f'/0/logfile_{thread}.dat'], npartitions=1)\n",
    "          for dir_ in dir_list for thread in range(30)], npartitions=10*30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "13ddd71d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dask.bag<from_sequence, npartitions=300>"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f34fb75e",
   "metadata": {},
   "source": [
    "## Pre-processing function for the bag_of_thread"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0c8d2be8",
   "metadata": {},
   "source": [
    "output_column_to_remove = ['ID', 'MHE_0', 'MCO_0', 'Radius_0', 'RHE_0','RCO_0', 'Luminosity_0', 'Temperature_0', 'Lambda_0',\n",
    "                               'Phase_0', 'PhaseBSE_0', 'Zams_0', 'MHE_1', 'MCO_1','Radius_1', 'RHE_1', 'RCO_1', \n",
    "                               'Luminosity_1', 'Temperature_1','Lambda_1', 'Phase_1', 'PhaseBSE_1', 'Zams_1']\n",
    "\n",
    "output_column_to_read = ['name', 'Mass_0', 'RemnantType_0', 'Mass_1', 'RemnantType_1',\n",
    "                         'Semimajor','Eccentricity','GWtime','BWorldtime']\n",
    "\n",
    "output_column_type = ['string', 'float64', 'int64', 'float64', 'int64',\n",
    "                      'float64', 'float64', 'float64', 'float64', 'int64']\n",
    "\n",
    "evolved_column_to_read = ['name', 'Mass_0', 'Z_0', 'SN_0', 'Mass_1', 'SN_1', 'a', 'e']\n",
    "\n",
    "\n",
    "evolved_column_type = ['string', 'float64', 'float64', 'string', 'float64', \n",
    "                      'string', 'float64', 'float64']\n",
    "\n",
    "#evolved_column_to_remove = ['#ID', 'spin_0', 'Tstart_0', 'spin_1', 'Tstart_1', 'Tend', 'Dtout', 'Seed']\n",
    "drop_list = ['RemnantType_0',  'RemnantType_1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "899704de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_bag_of_thread(bag_of_thread):\n",
    "    \n",
    "    output_column_to_read = ['name', 'Mass_0', 'RemnantType_0', 'Mass_1', 'RemnantType_1',\n",
    "                         'Semimajor','Eccentricity','GWtime','BWorldtime']\n",
    "\n",
    "    output_column_type = ['string', 'float64', 'int64', 'float64', 'int64',\n",
    "                      'float64', 'float64', 'float64', 'float64', 'int64']\n",
    "\n",
    "    evolved_column_to_read = ['name', 'Mass_0', 'Z_0', 'SN_0', 'Mass_1', 'SN_1', 'a', 'e']\n",
    "\n",
    "\n",
    "    evolved_column_type = ['string', 'float64', 'float64', 'string', 'float64', \n",
    "                      'string', 'float64', 'float64']\n",
    "\n",
    "    drop_list = ['RemnantType_0',  'RemnantType_1']\n",
    "    \n",
    "    \n",
    "    paths = bag_of_thread.take(3)\n",
    "\n",
    "   \n",
    "    #preprocessing output\n",
    "    \n",
    "    output = pd.read_csv(paths[0], usecols=output_column_to_read, dtype=dict(zip(output_column_to_read, output_column_type))).\\\n",
    "                rename(columns={'Mass_0':'Mass_0_out', 'Mass_1':'Mass_1_out'})\n",
    "\n",
    "    idxBHBH=(output.RemnantType_0==6) & (output.RemnantType_1==6) & (output.Semimajor.notnull())\n",
    "    output=output[idxBHBH]\n",
    "    \n",
    "    df=output\n",
    "    \n",
    "    \n",
    "    #preprocessing evolved\n",
    "    \n",
    "    alpha = float(re.findall(r\".+(?<=A)(.*)(?=L)\", paths[1])[0])\n",
    "    \n",
    "    evolved = pd.read_table(paths[1], sep='\\s+', usecols=evolved_column_to_read, dtype=dict(zip(evolved_column_to_read, evolved_column_type)))                \n",
    "    \n",
    "    evolved['alpha'] = alpha\n",
    "    \n",
    "    #preprocessing logfile\n",
    "    \n",
    "    logfile = pd.read_csv(paths[2], header=None)\n",
    "\n",
    "    df_RLO = logfile[0].str.extract(r\"B;((?:\\d*\\_)?\\d+);(\\d+);RLO_BEGIN;\").\\\n",
    "                dropna().\\\n",
    "                rename(columns={0:'name', 1:'ID'}).\\\n",
    "                groupby(['name']).\\\n",
    "                size().to_frame(name='RLO').\\\n",
    "                reset_index()\n",
    "\n",
    "    df_CE = logfile[0].str.extract(r\"B;((?:\\d*\\_)?\\d+);(\\d+);CE;\").\\\n",
    "                dropna().\\\n",
    "                rename(columns={0:'name', 1:'ID'}).\\\n",
    "                groupby(['name']).\\\n",
    "                size().to_frame(name='CE').\\\n",
    "                reset_index()\n",
    "\n",
    "    df_BSN = logfile[0].str.extract(r\"B;((?:\\d*\\_)?\\d+);(\\d+);BSN;\").\\\n",
    "                dropna().\\\n",
    "                rename(columns={0:'name', 1:'ID'}).\\\n",
    "                groupby(['name']).\\\n",
    "                size().to_frame(name='BSN').\\\n",
    "                reset_index()\n",
    "\n",
    "    \n",
    "    #merge\n",
    "    bhbh = evolved.merge(output, on=['name'], how='inner').\\\n",
    "                   merge(df_RLO, on=['name'], how='left').\\\n",
    "                   merge(df_CE,  on=['name'], how='left').\\\n",
    "                   merge(df_BSN, on=['name'], how='left').\\\n",
    "                   fillna(value=0).\\\n",
    "                   drop(columns=drop_list)\n",
    "    \n",
    "    #add some useful columns\n",
    "    bhbh['tdelay'] = bhbh['GWtime'] + bhbh['BWorldtime']\n",
    "\n",
    "    bhbh['Mass_max_out'] = bhbh['Mass_1_out']\n",
    "    bhbh['Mass_max_out'] = bhbh['Mass_max_out'].\\\n",
    "                            where(cond=(bhbh['Mass_max_out'] > bhbh['Mass_0_out']), other=bhbh['Mass_0_out'])\n",
    "\n",
    "    bhbh['q'] = bhbh['Mass_1_out']/bhbh['Mass_0_out']\n",
    "    bhbh['q'] = bhbh['q'].\\\n",
    "                where(cond=(bhbh['Mass_1_out'] < bhbh['Mass_0_out']), other=bhbh['Mass_0_out']/bhbh['Mass_1_out'])\n",
    "\n",
    "    bhbh['Mass_chirp'] = ((bhbh['Mass_0_out'] * bhbh['Mass_1_out'])**(3/5))/((bhbh['Mass_0_out'] + bhbh['Mass_1_out'])**(1/5))\n",
    "    \n",
    "    return bhbh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7392f7c2",
   "metadata": {},
   "source": [
    "## Map the preprocessing function to the bag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "005f1d5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.46 ms, sys: 282 Âµs, total: 5.75 ms\n",
      "Wall time: 5.41 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "bag_of_df = bag.map(preprocessing_bag_of_thread)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e92d2fa",
   "metadata": {},
   "source": [
    "## Compute and concat the dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "310d1d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# t_i=time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "e669bb75",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Requested dask.distributed scheduler but no Client active.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[0;32m<timed exec>:1\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/dask/base.py:310\u001b[0m, in \u001b[0;36mDaskMethodsMixin.compute\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    286\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    287\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Compute this dask collection\u001b[39;00m\n\u001b[1;32m    288\u001b[0m \n\u001b[1;32m    289\u001b[0m \u001b[38;5;124;03m    This turns a lazy Dask collection into its in-memory equivalent.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    308\u001b[0m \u001b[38;5;124;03m    dask.compute\u001b[39;00m\n\u001b[1;32m    309\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 310\u001b[0m     (result,) \u001b[38;5;241m=\u001b[39m \u001b[43mcompute\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraverse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    311\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/dask/base.py:595\u001b[0m, in \u001b[0;36mcompute\u001b[0;34m(traverse, optimize_graph, scheduler, get, *args, **kwargs)\u001b[0m\n\u001b[1;32m    592\u001b[0m     keys\u001b[38;5;241m.\u001b[39mappend(x\u001b[38;5;241m.\u001b[39m__dask_keys__())\n\u001b[1;32m    593\u001b[0m     postcomputes\u001b[38;5;241m.\u001b[39mappend(x\u001b[38;5;241m.\u001b[39m__dask_postcompute__())\n\u001b[0;32m--> 595\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mschedule\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdsk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    596\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m repack([f(r, \u001b[38;5;241m*\u001b[39ma) \u001b[38;5;28;01mfor\u001b[39;00m r, (f, a) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(results, postcomputes)])\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/distributed/client.py:3227\u001b[0m, in \u001b[0;36mClient.get\u001b[0;34m(self, dsk, keys, workers, allow_other_workers, resources, sync, asynchronous, direct, retries, priority, fifo_timeout, actors, **kwargs)\u001b[0m\n\u001b[1;32m   3225\u001b[0m         should_rejoin \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   3226\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3227\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgather\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpacked\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43masynchronous\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43masynchronous\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdirect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdirect\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3228\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m   3229\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m futures\u001b[38;5;241m.\u001b[39mvalues():\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/distributed/client.py:2361\u001b[0m, in \u001b[0;36mClient.gather\u001b[0;34m(self, futures, errors, direct, asynchronous)\u001b[0m\n\u001b[1;32m   2359\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2360\u001b[0m     local_worker \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 2361\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msync\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2362\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gather\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2363\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2364\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2365\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdirect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdirect\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2366\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlocal_worker\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_worker\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2367\u001b[0m \u001b[43m    \u001b[49m\u001b[43masynchronous\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43masynchronous\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2368\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/distributed/utils.py:351\u001b[0m, in \u001b[0;36mSyncMethodMixin.sync\u001b[0;34m(self, func, asynchronous, callback_timeout, *args, **kwargs)\u001b[0m\n\u001b[1;32m    349\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m future\n\u001b[1;32m    350\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 351\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msync\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback_timeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/distributed/utils.py:418\u001b[0m, in \u001b[0;36msync\u001b[0;34m(loop, func, callback_timeout, *args, **kwargs)\u001b[0m\n\u001b[1;32m    416\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m error:\n\u001b[1;32m    417\u001b[0m     typ, exc, tb \u001b[38;5;241m=\u001b[39m error\n\u001b[0;32m--> 418\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\u001b[38;5;241m.\u001b[39mwith_traceback(tb)\n\u001b[1;32m    419\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    420\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/distributed/utils.py:391\u001b[0m, in \u001b[0;36msync.<locals>.f\u001b[0;34m()\u001b[0m\n\u001b[1;32m    389\u001b[0m         future \u001b[38;5;241m=\u001b[39m wait_for(future, callback_timeout)\n\u001b[1;32m    390\u001b[0m     future \u001b[38;5;241m=\u001b[39m asyncio\u001b[38;5;241m.\u001b[39mensure_future(future)\n\u001b[0;32m--> 391\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01myield\u001b[39;00m future\n\u001b[1;32m    392\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m    393\u001b[0m     error \u001b[38;5;241m=\u001b[39m sys\u001b[38;5;241m.\u001b[39mexc_info()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tornado/gen.py:767\u001b[0m, in \u001b[0;36mRunner.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    765\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    766\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 767\u001b[0m         value \u001b[38;5;241m=\u001b[39m \u001b[43mfuture\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    768\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    769\u001b[0m         \u001b[38;5;66;03m# Save the exception for later. It's important that\u001b[39;00m\n\u001b[1;32m    770\u001b[0m         \u001b[38;5;66;03m# gen.throw() not be called inside this try/except block\u001b[39;00m\n\u001b[1;32m    771\u001b[0m         \u001b[38;5;66;03m# because that makes sys.exc_info behave unexpectedly.\u001b[39;00m\n\u001b[1;32m    772\u001b[0m         exc: Optional[\u001b[38;5;167;01mException\u001b[39;00m] \u001b[38;5;241m=\u001b[39m e\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/distributed/client.py:2224\u001b[0m, in \u001b[0;36mClient._gather\u001b[0;34m(self, futures, errors, direct, local_worker)\u001b[0m\n\u001b[1;32m   2222\u001b[0m         exc \u001b[38;5;241m=\u001b[39m CancelledError(key)\n\u001b[1;32m   2223\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2224\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m exception\u001b[38;5;241m.\u001b[39mwith_traceback(traceback)\n\u001b[1;32m   2225\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[1;32m   2226\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mskip\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/dask/bag/core.py:1856\u001b[0m, in \u001b[0;36mreify\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1854\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mreify\u001b[39m(seq):\n\u001b[1;32m   1855\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(seq, Iterator):\n\u001b[0;32m-> 1856\u001b[0m         seq \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(seq)\n\u001b[1;32m   1857\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(seq) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(seq[\u001b[38;5;241m0\u001b[39m], Iterator):\n\u001b[1;32m   1858\u001b[0m         seq \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mmap\u001b[39m(\u001b[38;5;28mlist\u001b[39m, seq))\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/dask/bag/core.py:2044\u001b[0m, in \u001b[0;36m__next__\u001b[0;34m()\u001b[0m\n\u001b[1;32m   2042\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwarg_keys, vals[\u001b[38;5;241m-\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnkws :]))\n\u001b[1;32m   2043\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m-> 2044\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf(\u001b[38;5;241m*\u001b[39mvals)\n",
      "Cell \u001b[0;32mIn[126], line 18\u001b[0m, in \u001b[0;36mpreprocessing_bag_of_thread\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m evolved_column_type \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstring\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfloat64\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfloat64\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstring\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfloat64\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[1;32m     13\u001b[0m                   \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstring\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfloat64\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfloat64\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     15\u001b[0m drop_list \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRemnantType_0\u001b[39m\u001b[38;5;124m'\u001b[39m,  \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRemnantType_1\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m---> 18\u001b[0m paths \u001b[38;5;241m=\u001b[39m bag_of_thread\u001b[38;5;241m.\u001b[39mtake(\u001b[38;5;241m3\u001b[39m)\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m#preprocessing output\u001b[39;00m\n\u001b[1;32m     23\u001b[0m output \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(paths[\u001b[38;5;241m0\u001b[39m], usecols\u001b[38;5;241m=\u001b[39moutput_column_to_read, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mdict\u001b[39m(\u001b[38;5;28mzip\u001b[39m(output_column_to_read, output_column_type)))\u001b[38;5;241m.\u001b[39m\\\n\u001b[1;32m     24\u001b[0m             rename(columns\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMass_0\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMass_0_out\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMass_1\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMass_1_out\u001b[39m\u001b[38;5;124m'\u001b[39m})\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/dask/bag/core.py:1457\u001b[0m, in \u001b[0;36mtake\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1454\u001b[0m b \u001b[38;5;241m=\u001b[39m Bag(graph, name, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m   1456\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m compute:\n\u001b[0;32m-> 1457\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m(b\u001b[38;5;241m.\u001b[39mcompute())\n\u001b[1;32m   1458\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1459\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m b\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/dask/base.py:310\u001b[0m, in \u001b[0;36mcompute\u001b[0;34m()\u001b[0m\n\u001b[1;32m    286\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    287\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Compute this dask collection\u001b[39;00m\n\u001b[1;32m    288\u001b[0m \n\u001b[1;32m    289\u001b[0m \u001b[38;5;124;03m    This turns a lazy Dask collection into its in-memory equivalent.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    308\u001b[0m \u001b[38;5;124;03m    dask.compute\u001b[39;00m\n\u001b[1;32m    309\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 310\u001b[0m     (result,) \u001b[38;5;241m=\u001b[39m compute(\u001b[38;5;28mself\u001b[39m, traverse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    311\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/dask/base.py:583\u001b[0m, in \u001b[0;36mcompute\u001b[0;34m()\u001b[0m\n\u001b[1;32m    580\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m collections:\n\u001b[1;32m    581\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m args\n\u001b[0;32m--> 583\u001b[0m schedule \u001b[38;5;241m=\u001b[39m get_scheduler(\n\u001b[1;32m    584\u001b[0m     scheduler\u001b[38;5;241m=\u001b[39mscheduler,\n\u001b[1;32m    585\u001b[0m     collections\u001b[38;5;241m=\u001b[39mcollections,\n\u001b[1;32m    586\u001b[0m     get\u001b[38;5;241m=\u001b[39mget,\n\u001b[1;32m    587\u001b[0m )\n\u001b[1;32m    589\u001b[0m dsk \u001b[38;5;241m=\u001b[39m collections_to_dsk(collections, optimize_graph, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    590\u001b[0m keys, postcomputes \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/dask/base.py:1398\u001b[0m, in \u001b[0;36mget_scheduler\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1394\u001b[0m     \u001b[38;5;66;03m# else:  # try to connect to remote scheduler with this name\u001b[39;00m\n\u001b[1;32m   1395\u001b[0m     \u001b[38;5;66;03m#     return get_client(scheduler).get\u001b[39;00m\n\u001b[1;32m   1397\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m config\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscheduler\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m-> 1398\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m get_scheduler(scheduler\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscheduler\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m   1400\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m config\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mget\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m   1401\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(get_err_msg)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/dask/base.py:1373\u001b[0m, in \u001b[0;36mget_scheduler\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1371\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m scheduler \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdask.distributed\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdistributed\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m   1372\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m client_available:\n\u001b[0;32m-> 1373\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m   1374\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRequested \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mscheduler\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m scheduler but no Client active.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1375\u001b[0m         )\n\u001b[1;32m   1376\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdistributed\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mworker\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_client\n\u001b[1;32m   1378\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m get_client()\u001b[38;5;241m.\u001b[39mget\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Requested dask.distributed scheduler but no Client active."
     ]
    }
   ],
   "source": [
    "%%time\n",
    "list_of_df=bag_of_df.compute()\n",
    "bhbh = dd.multi.concat(list_of_df).compute()\n",
    "t_f=time.time()\n",
    "\n",
    "# print(t_f-t_i, 'sec')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50735216",
   "metadata": {},
   "source": [
    "## Alternative way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "81b4f0a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.71 ms, sys: 1.63 ms, total: 6.34 ms\n",
      "Wall time: 8.28 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "bag_of_dicts = bag_of_df.map(lambda df: df.to_dict(orient='records')).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "1ff086f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bag_of_dicts.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "128882ad",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Requested dask.distributed scheduler but no Client active.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[0;32m<timed exec>:1\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/dask/base.py:310\u001b[0m, in \u001b[0;36mDaskMethodsMixin.compute\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    286\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    287\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Compute this dask collection\u001b[39;00m\n\u001b[1;32m    288\u001b[0m \n\u001b[1;32m    289\u001b[0m \u001b[38;5;124;03m    This turns a lazy Dask collection into its in-memory equivalent.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    308\u001b[0m \u001b[38;5;124;03m    dask.compute\u001b[39;00m\n\u001b[1;32m    309\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 310\u001b[0m     (result,) \u001b[38;5;241m=\u001b[39m \u001b[43mcompute\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraverse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    311\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/dask/base.py:595\u001b[0m, in \u001b[0;36mcompute\u001b[0;34m(traverse, optimize_graph, scheduler, get, *args, **kwargs)\u001b[0m\n\u001b[1;32m    592\u001b[0m     keys\u001b[38;5;241m.\u001b[39mappend(x\u001b[38;5;241m.\u001b[39m__dask_keys__())\n\u001b[1;32m    593\u001b[0m     postcomputes\u001b[38;5;241m.\u001b[39mappend(x\u001b[38;5;241m.\u001b[39m__dask_postcompute__())\n\u001b[0;32m--> 595\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mschedule\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdsk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    596\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m repack([f(r, \u001b[38;5;241m*\u001b[39ma) \u001b[38;5;28;01mfor\u001b[39;00m r, (f, a) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(results, postcomputes)])\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/distributed/client.py:3227\u001b[0m, in \u001b[0;36mClient.get\u001b[0;34m(self, dsk, keys, workers, allow_other_workers, resources, sync, asynchronous, direct, retries, priority, fifo_timeout, actors, **kwargs)\u001b[0m\n\u001b[1;32m   3225\u001b[0m         should_rejoin \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   3226\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3227\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgather\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpacked\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43masynchronous\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43masynchronous\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdirect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdirect\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3228\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m   3229\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m futures\u001b[38;5;241m.\u001b[39mvalues():\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/distributed/client.py:2361\u001b[0m, in \u001b[0;36mClient.gather\u001b[0;34m(self, futures, errors, direct, asynchronous)\u001b[0m\n\u001b[1;32m   2359\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2360\u001b[0m     local_worker \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 2361\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msync\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2362\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gather\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2363\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2364\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2365\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdirect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdirect\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2366\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlocal_worker\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_worker\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2367\u001b[0m \u001b[43m    \u001b[49m\u001b[43masynchronous\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43masynchronous\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2368\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/distributed/utils.py:351\u001b[0m, in \u001b[0;36mSyncMethodMixin.sync\u001b[0;34m(self, func, asynchronous, callback_timeout, *args, **kwargs)\u001b[0m\n\u001b[1;32m    349\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m future\n\u001b[1;32m    350\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 351\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msync\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback_timeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/distributed/utils.py:418\u001b[0m, in \u001b[0;36msync\u001b[0;34m(loop, func, callback_timeout, *args, **kwargs)\u001b[0m\n\u001b[1;32m    416\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m error:\n\u001b[1;32m    417\u001b[0m     typ, exc, tb \u001b[38;5;241m=\u001b[39m error\n\u001b[0;32m--> 418\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\u001b[38;5;241m.\u001b[39mwith_traceback(tb)\n\u001b[1;32m    419\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    420\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/distributed/utils.py:391\u001b[0m, in \u001b[0;36msync.<locals>.f\u001b[0;34m()\u001b[0m\n\u001b[1;32m    389\u001b[0m         future \u001b[38;5;241m=\u001b[39m wait_for(future, callback_timeout)\n\u001b[1;32m    390\u001b[0m     future \u001b[38;5;241m=\u001b[39m asyncio\u001b[38;5;241m.\u001b[39mensure_future(future)\n\u001b[0;32m--> 391\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01myield\u001b[39;00m future\n\u001b[1;32m    392\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m    393\u001b[0m     error \u001b[38;5;241m=\u001b[39m sys\u001b[38;5;241m.\u001b[39mexc_info()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tornado/gen.py:767\u001b[0m, in \u001b[0;36mRunner.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    765\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    766\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 767\u001b[0m         value \u001b[38;5;241m=\u001b[39m \u001b[43mfuture\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    768\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    769\u001b[0m         \u001b[38;5;66;03m# Save the exception for later. It's important that\u001b[39;00m\n\u001b[1;32m    770\u001b[0m         \u001b[38;5;66;03m# gen.throw() not be called inside this try/except block\u001b[39;00m\n\u001b[1;32m    771\u001b[0m         \u001b[38;5;66;03m# because that makes sys.exc_info behave unexpectedly.\u001b[39;00m\n\u001b[1;32m    772\u001b[0m         exc: Optional[\u001b[38;5;167;01mException\u001b[39;00m] \u001b[38;5;241m=\u001b[39m e\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/distributed/client.py:2224\u001b[0m, in \u001b[0;36mClient._gather\u001b[0;34m(self, futures, errors, direct, local_worker)\u001b[0m\n\u001b[1;32m   2222\u001b[0m         exc \u001b[38;5;241m=\u001b[39m CancelledError(key)\n\u001b[1;32m   2223\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2224\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m exception\u001b[38;5;241m.\u001b[39mwith_traceback(traceback)\n\u001b[1;32m   2225\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[1;32m   2226\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mskip\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/dask/optimization.py:992\u001b[0m, in \u001b[0;36m__call__\u001b[0;34m()\u001b[0m\n\u001b[1;32m    990\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minkeys):\n\u001b[1;32m    991\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m args, got \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minkeys), \u001b[38;5;28mlen\u001b[39m(args)))\n\u001b[0;32m--> 992\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m core\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdsk, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutkey, \u001b[38;5;28mdict\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minkeys, args)))\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/dask/core.py:151\u001b[0m, in \u001b[0;36mget\u001b[0;34m()\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m toposort(dsk):\n\u001b[1;32m    150\u001b[0m     task \u001b[38;5;241m=\u001b[39m dsk[key]\n\u001b[0;32m--> 151\u001b[0m     result \u001b[38;5;241m=\u001b[39m _execute_task(task, cache)\n\u001b[1;32m    152\u001b[0m     cache[key] \u001b[38;5;241m=\u001b[39m result\n\u001b[1;32m    153\u001b[0m result \u001b[38;5;241m=\u001b[39m _execute_task(out, cache)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/dask/core.py:121\u001b[0m, in \u001b[0;36m_execute_task\u001b[0;34m()\u001b[0m\n\u001b[1;32m    117\u001b[0m     func, args \u001b[38;5;241m=\u001b[39m arg[\u001b[38;5;241m0\u001b[39m], arg[\u001b[38;5;241m1\u001b[39m:]\n\u001b[1;32m    118\u001b[0m     \u001b[38;5;66;03m# Note: Don't assign the subtask results to a variable. numpy detects\u001b[39;00m\n\u001b[1;32m    119\u001b[0m     \u001b[38;5;66;03m# temporaries by their reference count and can execute certain\u001b[39;00m\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# operations in-place.\u001b[39;00m\n\u001b[0;32m--> 121\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39m(_execute_task(a, cache) \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m args))\n\u001b[1;32m    122\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ishashable(arg):\n\u001b[1;32m    123\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arg\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/dask/bag/core.py:2576\u001b[0m, in \u001b[0;36mto_dataframe\u001b[0;34m()\u001b[0m\n\u001b[1;32m   2573\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mto_dataframe\u001b[39m(seq, columns, dtypes):\n\u001b[1;32m   2574\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m-> 2576\u001b[0m     seq \u001b[38;5;241m=\u001b[39m reify(seq)\n\u001b[1;32m   2577\u001b[0m     \u001b[38;5;66;03m# pd.DataFrame expects lists, only copy if necessary\u001b[39;00m\n\u001b[1;32m   2578\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(seq, \u001b[38;5;28mlist\u001b[39m):\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/dask/bag/core.py:1856\u001b[0m, in \u001b[0;36mreify\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1854\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mreify\u001b[39m(seq):\n\u001b[1;32m   1855\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(seq, Iterator):\n\u001b[0;32m-> 1856\u001b[0m         seq \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(seq)\n\u001b[1;32m   1857\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(seq) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(seq[\u001b[38;5;241m0\u001b[39m], Iterator):\n\u001b[1;32m   1858\u001b[0m         seq \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mmap\u001b[39m(\u001b[38;5;28mlist\u001b[39m, seq))\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/dask/bag/core.py:2035\u001b[0m, in \u001b[0;36m__next__\u001b[0;34m()\u001b[0m\n\u001b[1;32m   2033\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__next__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m   2034\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 2035\u001b[0m         vals \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mnext\u001b[39m(i) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miters]\n\u001b[1;32m   2036\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m   2037\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_all_iterators_consumed()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/dask/bag/core.py:2035\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m()\u001b[0m\n\u001b[1;32m   2033\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__next__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m   2034\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 2035\u001b[0m         vals \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mnext\u001b[39m(i) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miters]\n\u001b[1;32m   2036\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m   2037\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_all_iterators_consumed()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/dask/bag/core.py:2044\u001b[0m, in \u001b[0;36m__next__\u001b[0;34m()\u001b[0m\n\u001b[1;32m   2042\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwarg_keys, vals[\u001b[38;5;241m-\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnkws :]))\n\u001b[1;32m   2043\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m-> 2044\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf(\u001b[38;5;241m*\u001b[39mvals)\n",
      "Cell \u001b[0;32mIn[126], line 18\u001b[0m, in \u001b[0;36mpreprocessing_bag_of_thread\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m evolved_column_type \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstring\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfloat64\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfloat64\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstring\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfloat64\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[1;32m     13\u001b[0m                   \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstring\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfloat64\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfloat64\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     15\u001b[0m drop_list \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRemnantType_0\u001b[39m\u001b[38;5;124m'\u001b[39m,  \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRemnantType_1\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m---> 18\u001b[0m paths \u001b[38;5;241m=\u001b[39m bag_of_thread\u001b[38;5;241m.\u001b[39mtake(\u001b[38;5;241m3\u001b[39m)\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m#preprocessing output\u001b[39;00m\n\u001b[1;32m     23\u001b[0m output \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(paths[\u001b[38;5;241m0\u001b[39m], usecols\u001b[38;5;241m=\u001b[39moutput_column_to_read, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mdict\u001b[39m(\u001b[38;5;28mzip\u001b[39m(output_column_to_read, output_column_type)))\u001b[38;5;241m.\u001b[39m\\\n\u001b[1;32m     24\u001b[0m             rename(columns\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMass_0\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMass_0_out\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMass_1\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMass_1_out\u001b[39m\u001b[38;5;124m'\u001b[39m})\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/dask/bag/core.py:1457\u001b[0m, in \u001b[0;36mtake\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1454\u001b[0m b \u001b[38;5;241m=\u001b[39m Bag(graph, name, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m   1456\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m compute:\n\u001b[0;32m-> 1457\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m(b\u001b[38;5;241m.\u001b[39mcompute())\n\u001b[1;32m   1458\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1459\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m b\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/dask/base.py:310\u001b[0m, in \u001b[0;36mcompute\u001b[0;34m()\u001b[0m\n\u001b[1;32m    286\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    287\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Compute this dask collection\u001b[39;00m\n\u001b[1;32m    288\u001b[0m \n\u001b[1;32m    289\u001b[0m \u001b[38;5;124;03m    This turns a lazy Dask collection into its in-memory equivalent.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    308\u001b[0m \u001b[38;5;124;03m    dask.compute\u001b[39;00m\n\u001b[1;32m    309\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 310\u001b[0m     (result,) \u001b[38;5;241m=\u001b[39m compute(\u001b[38;5;28mself\u001b[39m, traverse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    311\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/dask/base.py:583\u001b[0m, in \u001b[0;36mcompute\u001b[0;34m()\u001b[0m\n\u001b[1;32m    580\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m collections:\n\u001b[1;32m    581\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m args\n\u001b[0;32m--> 583\u001b[0m schedule \u001b[38;5;241m=\u001b[39m get_scheduler(\n\u001b[1;32m    584\u001b[0m     scheduler\u001b[38;5;241m=\u001b[39mscheduler,\n\u001b[1;32m    585\u001b[0m     collections\u001b[38;5;241m=\u001b[39mcollections,\n\u001b[1;32m    586\u001b[0m     get\u001b[38;5;241m=\u001b[39mget,\n\u001b[1;32m    587\u001b[0m )\n\u001b[1;32m    589\u001b[0m dsk \u001b[38;5;241m=\u001b[39m collections_to_dsk(collections, optimize_graph, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    590\u001b[0m keys, postcomputes \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/dask/base.py:1398\u001b[0m, in \u001b[0;36mget_scheduler\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1394\u001b[0m     \u001b[38;5;66;03m# else:  # try to connect to remote scheduler with this name\u001b[39;00m\n\u001b[1;32m   1395\u001b[0m     \u001b[38;5;66;03m#     return get_client(scheduler).get\u001b[39;00m\n\u001b[1;32m   1397\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m config\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscheduler\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m-> 1398\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m get_scheduler(scheduler\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscheduler\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m   1400\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m config\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mget\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m   1401\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(get_err_msg)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/dask/base.py:1373\u001b[0m, in \u001b[0;36mget_scheduler\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1371\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m scheduler \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdask.distributed\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdistributed\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m   1372\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m client_available:\n\u001b[0;32m-> 1373\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m   1374\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRequested \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mscheduler\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m scheduler but no Client active.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1375\u001b[0m         )\n\u001b[1;32m   1376\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdistributed\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mworker\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_client\n\u001b[1;32m   1378\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m get_client()\u001b[38;5;241m.\u001b[39mget\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Requested dask.distributed scheduler but no Client active."
     ]
    }
   ],
   "source": [
    "%%time\n",
    "bhbh = bag_of_dicts.to_dataframe().compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "53265139",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cluster.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "50c0a353",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bhbh.visualize()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e81fb0b",
   "metadata": {},
   "source": [
    "## Final dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "0c4cf82f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7.01 ms, sys: 0 ns, total: 7.01 ms\n",
      "Wall time: 8.13 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "head=bhbh.head()\n",
    "head.to_csv('test_su_test_della_bag_di_bag_aggiornato')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "23815756",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.0K -rw-rw-r-- 1 ubuntu ubuntu 1.2K Jun 13 14:19 test_su_test_della_bag_di_bag_aggiornato\r\n"
     ]
    }
   ],
   "source": [
    "! ls -lsh test_su_test_della_bag_di_bag_aggiornato"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
